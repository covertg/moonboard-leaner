{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moon.data\n",
    "import moon.problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = moon.data.read_problems('data/cleaned_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30991, 18, 11) (30991, 17)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([p.array for p in probs])\n",
    "y = np.array([p.grade.ordinal for p in probs])\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class OrdinalAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='ordinal_acc_within_k', k=0, threshold=0.5, **kwargs):\n",
    "        super(OrdinalAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "        self.total = self.add_weight(name='total', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # See section 2.3: http://calla.rnet.missouri.edu/cheng_courses/rank.pdf\n",
    "        pred_thresh = tf.cast(y_pred >= self.threshold, 'int8')\n",
    "        true_thresh = tf.cast(y_true >= self.threshold, 'int8')\n",
    "        pred_idx = tf.argmin(pred_thresh, axis=-1) - 1\n",
    "        true_idx = tf.argmin(true_thresh, axis=-1) - 1\n",
    "        distance_bools = (tf.abs(pred_idx - true_idx) <= self.k)\n",
    "        correct = tf.reduce_sum(tf.cast(distance_bools, 'float32'))\n",
    "        incorrect = tf.reduce_sum(tf.cast(tf.logical_not(distance_bools), 'float32'))\n",
    "        self.total.assign_add(correct)\n",
    "        self.count.assign_add(correct + incorrect)\n",
    "    \n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    \n",
    "# α = 0.3\n",
    "p = .4\n",
    "input_shape = moon.problem.Problem.GRID_SHAPE\n",
    "hiddens = [16, 16]\n",
    "hidden_activation = 'swish'\n",
    "output_shape = moon.problem.Grade.N_GRADES\n",
    "output_activation = 'sigmoid'\n",
    "loss = 'mse'\n",
    "adam_lr = 1e-4\n",
    "\n",
    "metrics = [OrdinalAccuracy(name='acc0', k=0), OrdinalAccuracy(name='acc1', k=1), OrdinalAccuracy(name='acc2', k=2)]\n",
    "optim = tf.keras.optimizers.Adam(lr=adam_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_x = layers.Input(shape=input_shape)\n",
    "features = layers.Flatten()(in_x)\n",
    "for nodes in hiddens:\n",
    "    features = layers.Dense(nodes, activation=hidden_activation)(features)\n",
    "    # features = layers.ReLU(α)(features)\n",
    "    if p > 0: features = layers.Dropout(p)(features)\n",
    "out_y = layers.Dense(output_shape, activation=output_activation)(features)\n",
    "\n",
    "model = tf.keras.Model(in_x, out_y, name='Feedforward_classifier')\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24793, 18, 11) (6198, 18, 11)\n"
     ]
    }
   ],
   "source": [
    "split = 0.2\n",
    "indices = np.arange(len(probs))\n",
    "np.random.shuffle(indices)\n",
    "n_test = int(len(probs) * split)\n",
    "\n",
    "x_train, y_train = x[indices[n_test:]], y[indices[n_test:]]\n",
    "x_test, y_test = x[indices[0:n_test]], y[indices[0:n_test]]\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.2387 - acc0: 0.0385 - acc1: 0.1199 - acc2: 0.2048 - val_loss: 0.2173 - val_acc0: 0.1912 - val_acc1: 0.4450 - val_acc2: 0.7757\n",
      "Epoch 2/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.1775 - acc0: 0.1289 - acc1: 0.3719 - acc2: 0.5724 - val_loss: 0.1204 - val_acc0: 0.1481 - val_acc1: 0.4155 - val_acc2: 0.8414\n",
      "Epoch 3/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.1141 - acc0: 0.1671 - acc1: 0.4571 - acc2: 0.7098 - val_loss: 0.0802 - val_acc0: 0.1481 - val_acc1: 0.4397 - val_acc2: 0.8408\n",
      "Epoch 4/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0933 - acc0: 0.1786 - acc1: 0.4788 - acc2: 0.7352 - val_loss: 0.0722 - val_acc0: 0.1488 - val_acc1: 0.4945 - val_acc2: 0.8401\n",
      "Epoch 5/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0850 - acc0: 0.1899 - acc1: 0.4898 - acc2: 0.7393 - val_loss: 0.0695 - val_acc0: 0.1484 - val_acc1: 0.5342 - val_acc2: 0.8391\n",
      "Epoch 6/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0809 - acc0: 0.1938 - acc1: 0.4978 - acc2: 0.7470 - val_loss: 0.0678 - val_acc0: 0.1521 - val_acc1: 0.5532 - val_acc2: 0.8393\n",
      "Epoch 7/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0776 - acc0: 0.2063 - acc1: 0.5081 - acc2: 0.7532 - val_loss: 0.0661 - val_acc0: 0.1662 - val_acc1: 0.6007 - val_acc2: 0.8374\n",
      "Epoch 8/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0751 - acc0: 0.2120 - acc1: 0.5190 - acc2: 0.7573 - val_loss: 0.0644 - val_acc0: 0.1989 - val_acc1: 0.6192 - val_acc2: 0.8359\n",
      "Epoch 9/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0726 - acc0: 0.2318 - acc1: 0.5283 - acc2: 0.7657 - val_loss: 0.0628 - val_acc0: 0.2227 - val_acc1: 0.6215 - val_acc2: 0.8380\n",
      "Epoch 10/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0709 - acc0: 0.2337 - acc1: 0.5336 - acc2: 0.7677 - val_loss: 0.0611 - val_acc0: 0.2543 - val_acc1: 0.6363 - val_acc2: 0.8401\n",
      "Epoch 11/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0685 - acc0: 0.2464 - acc1: 0.5497 - acc2: 0.7809 - val_loss: 0.0594 - val_acc0: 0.2817 - val_acc1: 0.6492 - val_acc2: 0.8438\n",
      "Epoch 12/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0667 - acc0: 0.2533 - acc1: 0.5605 - acc2: 0.7849 - val_loss: 0.0579 - val_acc0: 0.2972 - val_acc1: 0.6563 - val_acc2: 0.8461\n",
      "Epoch 13/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0650 - acc0: 0.2672 - acc1: 0.5708 - acc2: 0.7899 - val_loss: 0.0564 - val_acc0: 0.3117 - val_acc1: 0.6659 - val_acc2: 0.8477\n",
      "Epoch 14/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0637 - acc0: 0.2746 - acc1: 0.5794 - acc2: 0.7937 - val_loss: 0.0552 - val_acc0: 0.3278 - val_acc1: 0.6680 - val_acc2: 0.8485\n",
      "Epoch 15/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0622 - acc0: 0.2817 - acc1: 0.5902 - acc2: 0.7967 - val_loss: 0.0541 - val_acc0: 0.3375 - val_acc1: 0.6722 - val_acc2: 0.8467\n",
      "Epoch 16/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0610 - acc0: 0.2900 - acc1: 0.5923 - acc2: 0.8003 - val_loss: 0.0531 - val_acc0: 0.3432 - val_acc1: 0.6731 - val_acc2: 0.8462\n",
      "Epoch 17/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0599 - acc0: 0.2958 - acc1: 0.6014 - acc2: 0.8043 - val_loss: 0.0522 - val_acc0: 0.3498 - val_acc1: 0.6762 - val_acc2: 0.8470\n",
      "Epoch 18/300\n",
      "388/388 [==============================] - 1s 4ms/step - loss: 0.0588 - acc0: 0.2979 - acc1: 0.6098 - acc2: 0.8134 - val_loss: 0.0515 - val_acc0: 0.3543 - val_acc1: 0.6797 - val_acc2: 0.8475\n",
      "Epoch 19/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0582 - acc0: 0.3058 - acc1: 0.6139 - acc2: 0.8146 - val_loss: 0.0509 - val_acc0: 0.3569 - val_acc1: 0.6838 - val_acc2: 0.8498\n",
      "Epoch 20/300\n",
      "388/388 [==============================] - 1s 4ms/step - loss: 0.0571 - acc0: 0.3070 - acc1: 0.6183 - acc2: 0.8183 - val_loss: 0.0504 - val_acc0: 0.3627 - val_acc1: 0.6834 - val_acc2: 0.8520\n",
      "Epoch 21/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0565 - acc0: 0.3145 - acc1: 0.6253 - acc2: 0.8248 - val_loss: 0.0500 - val_acc0: 0.3650 - val_acc1: 0.6841 - val_acc2: 0.8525\n",
      "Epoch 22/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0560 - acc0: 0.3163 - acc1: 0.6265 - acc2: 0.8267 - val_loss: 0.0496 - val_acc0: 0.3645 - val_acc1: 0.6841 - val_acc2: 0.8561\n",
      "Epoch 23/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0558 - acc0: 0.3162 - acc1: 0.6273 - acc2: 0.8278 - val_loss: 0.0493 - val_acc0: 0.3658 - val_acc1: 0.6849 - val_acc2: 0.8585\n",
      "Epoch 24/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0549 - acc0: 0.3263 - acc1: 0.6349 - acc2: 0.8341 - val_loss: 0.0491 - val_acc0: 0.3674 - val_acc1: 0.6847 - val_acc2: 0.8588\n",
      "Epoch 25/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0552 - acc0: 0.3195 - acc1: 0.6305 - acc2: 0.8343 - val_loss: 0.0488 - val_acc0: 0.3659 - val_acc1: 0.6864 - val_acc2: 0.8601\n",
      "Epoch 26/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0543 - acc0: 0.3216 - acc1: 0.6403 - acc2: 0.8376 - val_loss: 0.0486 - val_acc0: 0.3666 - val_acc1: 0.6884 - val_acc2: 0.8624\n",
      "Epoch 27/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0543 - acc0: 0.3216 - acc1: 0.6352 - acc2: 0.8414 - val_loss: 0.0485 - val_acc0: 0.3696 - val_acc1: 0.6876 - val_acc2: 0.8632\n",
      "Epoch 28/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0538 - acc0: 0.3264 - acc1: 0.6391 - acc2: 0.8422 - val_loss: 0.0483 - val_acc0: 0.3714 - val_acc1: 0.6883 - val_acc2: 0.8637\n",
      "Epoch 29/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0536 - acc0: 0.3247 - acc1: 0.6417 - acc2: 0.8419 - val_loss: 0.0482 - val_acc0: 0.3711 - val_acc1: 0.6881 - val_acc2: 0.8650\n",
      "Epoch 30/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0532 - acc0: 0.3305 - acc1: 0.6446 - acc2: 0.8457 - val_loss: 0.0481 - val_acc0: 0.3719 - val_acc1: 0.6904 - val_acc2: 0.8661\n",
      "Epoch 31/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0530 - acc0: 0.3300 - acc1: 0.6474 - acc2: 0.8477 - val_loss: 0.0480 - val_acc0: 0.3732 - val_acc1: 0.6914 - val_acc2: 0.8674\n",
      "Epoch 32/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0530 - acc0: 0.3273 - acc1: 0.6446 - acc2: 0.8466 - val_loss: 0.0479 - val_acc0: 0.3756 - val_acc1: 0.6896 - val_acc2: 0.8679\n",
      "Epoch 33/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0528 - acc0: 0.3309 - acc1: 0.6479 - acc2: 0.8474 - val_loss: 0.0478 - val_acc0: 0.3737 - val_acc1: 0.6905 - val_acc2: 0.8704\n",
      "Epoch 34/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0525 - acc0: 0.3330 - acc1: 0.6498 - acc2: 0.8492 - val_loss: 0.0477 - val_acc0: 0.3729 - val_acc1: 0.6902 - val_acc2: 0.8711\n",
      "Epoch 35/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0525 - acc0: 0.3352 - acc1: 0.6484 - acc2: 0.8464 - val_loss: 0.0476 - val_acc0: 0.3733 - val_acc1: 0.6901 - val_acc2: 0.8712\n",
      "Epoch 36/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0523 - acc0: 0.3378 - acc1: 0.6514 - acc2: 0.8499 - val_loss: 0.0476 - val_acc0: 0.3759 - val_acc1: 0.6914 - val_acc2: 0.8722\n",
      "Epoch 37/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0522 - acc0: 0.3360 - acc1: 0.6499 - acc2: 0.8527 - val_loss: 0.0475 - val_acc0: 0.3750 - val_acc1: 0.6923 - val_acc2: 0.8737\n",
      "Epoch 38/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0518 - acc0: 0.3374 - acc1: 0.6530 - acc2: 0.8508 - val_loss: 0.0474 - val_acc0: 0.3772 - val_acc1: 0.6912 - val_acc2: 0.8738\n",
      "Epoch 39/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0521 - acc0: 0.3388 - acc1: 0.6540 - acc2: 0.8508 - val_loss: 0.0473 - val_acc0: 0.3785 - val_acc1: 0.6933 - val_acc2: 0.8746\n",
      "Epoch 40/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0517 - acc0: 0.3388 - acc1: 0.6536 - acc2: 0.8530 - val_loss: 0.0473 - val_acc0: 0.3767 - val_acc1: 0.6936 - val_acc2: 0.8754\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0516 - acc0: 0.3381 - acc1: 0.6579 - acc2: 0.8552 - val_loss: 0.0472 - val_acc0: 0.3777 - val_acc1: 0.6939 - val_acc2: 0.8766\n",
      "Epoch 42/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0516 - acc0: 0.3368 - acc1: 0.6540 - acc2: 0.8555 - val_loss: 0.0472 - val_acc0: 0.3782 - val_acc1: 0.6944 - val_acc2: 0.8767\n",
      "Epoch 43/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0512 - acc0: 0.3407 - acc1: 0.6593 - acc2: 0.8580 - val_loss: 0.0471 - val_acc0: 0.3796 - val_acc1: 0.6951 - val_acc2: 0.8779\n",
      "Epoch 44/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0513 - acc0: 0.3408 - acc1: 0.6565 - acc2: 0.8566 - val_loss: 0.0470 - val_acc0: 0.3785 - val_acc1: 0.6933 - val_acc2: 0.8782\n",
      "Epoch 45/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0510 - acc0: 0.3409 - acc1: 0.6597 - acc2: 0.8577 - val_loss: 0.0470 - val_acc0: 0.3816 - val_acc1: 0.6936 - val_acc2: 0.8785\n",
      "Epoch 46/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0511 - acc0: 0.3452 - acc1: 0.6607 - acc2: 0.8564 - val_loss: 0.0469 - val_acc0: 0.3817 - val_acc1: 0.6949 - val_acc2: 0.8793\n",
      "Epoch 47/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0512 - acc0: 0.3390 - acc1: 0.6591 - acc2: 0.8568 - val_loss: 0.0469 - val_acc0: 0.3813 - val_acc1: 0.6949 - val_acc2: 0.8795\n",
      "Epoch 48/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0508 - acc0: 0.3420 - acc1: 0.6608 - acc2: 0.8589 - val_loss: 0.0468 - val_acc0: 0.3827 - val_acc1: 0.6951 - val_acc2: 0.8801\n",
      "Epoch 49/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0508 - acc0: 0.3463 - acc1: 0.6611 - acc2: 0.8585 - val_loss: 0.0467 - val_acc0: 0.3809 - val_acc1: 0.6943 - val_acc2: 0.8808\n",
      "Epoch 50/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0510 - acc0: 0.3406 - acc1: 0.6612 - acc2: 0.8575 - val_loss: 0.0467 - val_acc0: 0.3835 - val_acc1: 0.6951 - val_acc2: 0.8808\n",
      "Epoch 51/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0507 - acc0: 0.3408 - acc1: 0.6610 - acc2: 0.8592 - val_loss: 0.0466 - val_acc0: 0.3825 - val_acc1: 0.6947 - val_acc2: 0.8814\n",
      "Epoch 52/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0505 - acc0: 0.3463 - acc1: 0.6633 - acc2: 0.8618 - val_loss: 0.0466 - val_acc0: 0.3829 - val_acc1: 0.6946 - val_acc2: 0.8814\n",
      "Epoch 53/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0503 - acc0: 0.3464 - acc1: 0.6650 - acc2: 0.8613 - val_loss: 0.0465 - val_acc0: 0.3845 - val_acc1: 0.6951 - val_acc2: 0.8811\n",
      "Epoch 54/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0505 - acc0: 0.3434 - acc1: 0.6627 - acc2: 0.8621 - val_loss: 0.0465 - val_acc0: 0.3832 - val_acc1: 0.6959 - val_acc2: 0.8817\n",
      "Epoch 55/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0504 - acc0: 0.3496 - acc1: 0.6660 - acc2: 0.8617 - val_loss: 0.0465 - val_acc0: 0.3833 - val_acc1: 0.6946 - val_acc2: 0.8814\n",
      "Epoch 56/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0502 - acc0: 0.3474 - acc1: 0.6653 - acc2: 0.8621 - val_loss: 0.0464 - val_acc0: 0.3845 - val_acc1: 0.6949 - val_acc2: 0.8822\n",
      "Epoch 57/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0503 - acc0: 0.3435 - acc1: 0.6669 - acc2: 0.8625 - val_loss: 0.0463 - val_acc0: 0.3833 - val_acc1: 0.6955 - val_acc2: 0.8821\n",
      "Epoch 58/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0503 - acc0: 0.3474 - acc1: 0.6657 - acc2: 0.8615 - val_loss: 0.0463 - val_acc0: 0.3858 - val_acc1: 0.6965 - val_acc2: 0.8827\n",
      "Epoch 59/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0500 - acc0: 0.3478 - acc1: 0.6697 - acc2: 0.8637 - val_loss: 0.0463 - val_acc0: 0.3863 - val_acc1: 0.6964 - val_acc2: 0.8833\n",
      "Epoch 60/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0501 - acc0: 0.3476 - acc1: 0.6670 - acc2: 0.8648 - val_loss: 0.0462 - val_acc0: 0.3856 - val_acc1: 0.6970 - val_acc2: 0.8840\n",
      "Epoch 61/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0501 - acc0: 0.3481 - acc1: 0.6662 - acc2: 0.8623 - val_loss: 0.0462 - val_acc0: 0.3867 - val_acc1: 0.6976 - val_acc2: 0.8842\n",
      "Epoch 62/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0497 - acc0: 0.3513 - acc1: 0.6714 - acc2: 0.8669 - val_loss: 0.0461 - val_acc0: 0.3880 - val_acc1: 0.6970 - val_acc2: 0.8843\n",
      "Epoch 63/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0499 - acc0: 0.3476 - acc1: 0.6693 - acc2: 0.8643 - val_loss: 0.0461 - val_acc0: 0.3867 - val_acc1: 0.6980 - val_acc2: 0.8853\n",
      "Epoch 64/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0498 - acc0: 0.3487 - acc1: 0.6711 - acc2: 0.8650 - val_loss: 0.0460 - val_acc0: 0.3880 - val_acc1: 0.6996 - val_acc2: 0.8850\n",
      "Epoch 65/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0496 - acc0: 0.3528 - acc1: 0.6712 - acc2: 0.8659 - val_loss: 0.0460 - val_acc0: 0.3872 - val_acc1: 0.7001 - val_acc2: 0.8853\n",
      "Epoch 66/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0498 - acc0: 0.3507 - acc1: 0.6690 - acc2: 0.8680 - val_loss: 0.0459 - val_acc0: 0.3882 - val_acc1: 0.7014 - val_acc2: 0.8858\n",
      "Epoch 67/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0494 - acc0: 0.3488 - acc1: 0.6730 - acc2: 0.8670 - val_loss: 0.0459 - val_acc0: 0.3882 - val_acc1: 0.7007 - val_acc2: 0.8856\n",
      "Epoch 68/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0495 - acc0: 0.3511 - acc1: 0.6743 - acc2: 0.8665 - val_loss: 0.0458 - val_acc0: 0.3874 - val_acc1: 0.7020 - val_acc2: 0.8863\n",
      "Epoch 69/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0496 - acc0: 0.3479 - acc1: 0.6726 - acc2: 0.8661 - val_loss: 0.0458 - val_acc0: 0.3877 - val_acc1: 0.7033 - val_acc2: 0.8867\n",
      "Epoch 70/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0493 - acc0: 0.3498 - acc1: 0.6741 - acc2: 0.8681 - val_loss: 0.0458 - val_acc0: 0.3875 - val_acc1: 0.7033 - val_acc2: 0.8874\n",
      "Epoch 71/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0493 - acc0: 0.3537 - acc1: 0.6743 - acc2: 0.8665 - val_loss: 0.0457 - val_acc0: 0.3882 - val_acc1: 0.7038 - val_acc2: 0.8872\n",
      "Epoch 72/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0492 - acc0: 0.3520 - acc1: 0.6731 - acc2: 0.8695 - val_loss: 0.0456 - val_acc0: 0.3884 - val_acc1: 0.7057 - val_acc2: 0.8884\n",
      "Epoch 73/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0494 - acc0: 0.3530 - acc1: 0.6746 - acc2: 0.8683 - val_loss: 0.0456 - val_acc0: 0.3879 - val_acc1: 0.7062 - val_acc2: 0.8877\n",
      "Epoch 74/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0492 - acc0: 0.3568 - acc1: 0.6777 - acc2: 0.8683 - val_loss: 0.0456 - val_acc0: 0.3900 - val_acc1: 0.7047 - val_acc2: 0.8875\n",
      "Epoch 75/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0493 - acc0: 0.3530 - acc1: 0.6746 - acc2: 0.8679 - val_loss: 0.0455 - val_acc0: 0.3893 - val_acc1: 0.7057 - val_acc2: 0.8887\n",
      "Epoch 76/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0493 - acc0: 0.3519 - acc1: 0.6731 - acc2: 0.8690 - val_loss: 0.0455 - val_acc0: 0.3904 - val_acc1: 0.7068 - val_acc2: 0.8895\n",
      "Epoch 77/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0491 - acc0: 0.3559 - acc1: 0.6748 - acc2: 0.8684 - val_loss: 0.0455 - val_acc0: 0.3901 - val_acc1: 0.7075 - val_acc2: 0.8895\n",
      "Epoch 78/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0490 - acc0: 0.3572 - acc1: 0.6765 - acc2: 0.8691 - val_loss: 0.0454 - val_acc0: 0.3901 - val_acc1: 0.7067 - val_acc2: 0.8901\n",
      "Epoch 79/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0489 - acc0: 0.3530 - acc1: 0.6763 - acc2: 0.8711 - val_loss: 0.0454 - val_acc0: 0.3890 - val_acc1: 0.7089 - val_acc2: 0.8911\n",
      "Epoch 80/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0490 - acc0: 0.3540 - acc1: 0.6767 - acc2: 0.8698 - val_loss: 0.0453 - val_acc0: 0.3888 - val_acc1: 0.7086 - val_acc2: 0.8916\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0490 - acc0: 0.3565 - acc1: 0.6757 - acc2: 0.8686 - val_loss: 0.0453 - val_acc0: 0.3888 - val_acc1: 0.7081 - val_acc2: 0.8909\n",
      "Epoch 82/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0488 - acc0: 0.3562 - acc1: 0.6770 - acc2: 0.8696 - val_loss: 0.0452 - val_acc0: 0.3882 - val_acc1: 0.7093 - val_acc2: 0.8913\n",
      "Epoch 83/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0486 - acc0: 0.3572 - acc1: 0.6793 - acc2: 0.8715 - val_loss: 0.0452 - val_acc0: 0.3892 - val_acc1: 0.7089 - val_acc2: 0.8921\n",
      "Epoch 84/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0487 - acc0: 0.3534 - acc1: 0.6810 - acc2: 0.8716 - val_loss: 0.0451 - val_acc0: 0.3896 - val_acc1: 0.7097 - val_acc2: 0.8919\n",
      "Epoch 85/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0487 - acc0: 0.3537 - acc1: 0.6794 - acc2: 0.8717 - val_loss: 0.0451 - val_acc0: 0.3895 - val_acc1: 0.7096 - val_acc2: 0.8924\n",
      "Epoch 86/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0486 - acc0: 0.3562 - acc1: 0.6769 - acc2: 0.8720 - val_loss: 0.0451 - val_acc0: 0.3895 - val_acc1: 0.7101 - val_acc2: 0.8927\n",
      "Epoch 87/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0486 - acc0: 0.3577 - acc1: 0.6802 - acc2: 0.8723 - val_loss: 0.0450 - val_acc0: 0.3893 - val_acc1: 0.7102 - val_acc2: 0.8943\n",
      "Epoch 88/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0485 - acc0: 0.3574 - acc1: 0.6805 - acc2: 0.8736 - val_loss: 0.0450 - val_acc0: 0.3903 - val_acc1: 0.7106 - val_acc2: 0.8932\n",
      "Epoch 89/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0484 - acc0: 0.3585 - acc1: 0.6826 - acc2: 0.8736 - val_loss: 0.0449 - val_acc0: 0.3892 - val_acc1: 0.7101 - val_acc2: 0.8942\n",
      "Epoch 90/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0484 - acc0: 0.3574 - acc1: 0.6820 - acc2: 0.8735 - val_loss: 0.0449 - val_acc0: 0.3887 - val_acc1: 0.7112 - val_acc2: 0.8945\n",
      "Epoch 91/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0482 - acc0: 0.3594 - acc1: 0.6808 - acc2: 0.8734 - val_loss: 0.0448 - val_acc0: 0.3888 - val_acc1: 0.7110 - val_acc2: 0.8948\n",
      "Epoch 92/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0482 - acc0: 0.3579 - acc1: 0.6847 - acc2: 0.8750 - val_loss: 0.0448 - val_acc0: 0.3916 - val_acc1: 0.7117 - val_acc2: 0.8955\n",
      "Epoch 93/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0484 - acc0: 0.3577 - acc1: 0.6839 - acc2: 0.8731 - val_loss: 0.0447 - val_acc0: 0.3888 - val_acc1: 0.7118 - val_acc2: 0.8959\n",
      "Epoch 94/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0484 - acc0: 0.3568 - acc1: 0.6795 - acc2: 0.8727 - val_loss: 0.0447 - val_acc0: 0.3906 - val_acc1: 0.7120 - val_acc2: 0.8959\n",
      "Epoch 95/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0481 - acc0: 0.3598 - acc1: 0.6813 - acc2: 0.8759 - val_loss: 0.0447 - val_acc0: 0.3911 - val_acc1: 0.7130 - val_acc2: 0.8958\n",
      "Epoch 96/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0482 - acc0: 0.3572 - acc1: 0.6820 - acc2: 0.8758 - val_loss: 0.0446 - val_acc0: 0.3935 - val_acc1: 0.7123 - val_acc2: 0.8964\n",
      "Epoch 97/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0481 - acc0: 0.3570 - acc1: 0.6839 - acc2: 0.8758 - val_loss: 0.0446 - val_acc0: 0.3938 - val_acc1: 0.7128 - val_acc2: 0.8958\n",
      "Epoch 98/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0480 - acc0: 0.3600 - acc1: 0.6863 - acc2: 0.8771 - val_loss: 0.0445 - val_acc0: 0.3925 - val_acc1: 0.7136 - val_acc2: 0.8963\n",
      "Epoch 99/300\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0481 - acc0: 0.3584 - acc1: 0.6861 - acc2: 0.8756 - val_loss: 0.0445 - val_acc0: 0.3934 - val_acc1: 0.7147 - val_acc2: 0.8967\n",
      "Epoch 100/300\n",
      "388/388 [==============================] - 2s 6ms/step - loss: 0.0478 - acc0: 0.3618 - acc1: 0.6872 - acc2: 0.8754 - val_loss: 0.0444 - val_acc0: 0.3916 - val_acc1: 0.7165 - val_acc2: 0.8984\n",
      "Epoch 101/300\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.0480 - acc0: 0.3584 - acc1: 0.6864 - acc2: 0.8755 - val_loss: 0.0444 - val_acc0: 0.3932 - val_acc1: 0.7151 - val_acc2: 0.8972\n",
      "Epoch 102/300\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0480 - acc0: 0.3540 - acc1: 0.6836 - acc2: 0.8773 - val_loss: 0.0444 - val_acc0: 0.3940 - val_acc1: 0.7141 - val_acc2: 0.8969\n",
      "Epoch 103/300\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.0478 - acc0: 0.3596 - acc1: 0.6864 - acc2: 0.8784 - val_loss: 0.0443 - val_acc0: 0.3943 - val_acc1: 0.7154 - val_acc2: 0.8972\n",
      "Epoch 104/300\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.0479 - acc0: 0.3616 - acc1: 0.6855 - acc2: 0.8759 - val_loss: 0.0443 - val_acc0: 0.3935 - val_acc1: 0.7157 - val_acc2: 0.8974\n",
      "Epoch 105/300\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0476 - acc0: 0.3626 - acc1: 0.6888 - acc2: 0.8780 - val_loss: 0.0443 - val_acc0: 0.3948 - val_acc1: 0.7154 - val_acc2: 0.8984\n",
      "Epoch 106/300\n",
      "388/388 [==============================] - 1s 4ms/step - loss: 0.0476 - acc0: 0.3639 - acc1: 0.6909 - acc2: 0.8774 - val_loss: 0.0442 - val_acc0: 0.3942 - val_acc1: 0.7160 - val_acc2: 0.8985\n",
      "Epoch 107/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0478 - acc0: 0.3611 - acc1: 0.6876 - acc2: 0.8764 - val_loss: 0.0442 - val_acc0: 0.3945 - val_acc1: 0.7167 - val_acc2: 0.8987\n",
      "Epoch 108/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0477 - acc0: 0.3635 - acc1: 0.6882 - acc2: 0.8773 - val_loss: 0.0441 - val_acc0: 0.3953 - val_acc1: 0.7165 - val_acc2: 0.8993\n",
      "Epoch 109/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0475 - acc0: 0.3612 - acc1: 0.6873 - acc2: 0.8762 - val_loss: 0.0441 - val_acc0: 0.3953 - val_acc1: 0.7154 - val_acc2: 0.8992\n",
      "Epoch 110/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0476 - acc0: 0.3590 - acc1: 0.6864 - acc2: 0.8794 - val_loss: 0.0441 - val_acc0: 0.3945 - val_acc1: 0.7159 - val_acc2: 0.8992\n",
      "Epoch 111/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0476 - acc0: 0.3617 - acc1: 0.6875 - acc2: 0.8785 - val_loss: 0.0440 - val_acc0: 0.3946 - val_acc1: 0.7173 - val_acc2: 0.9000\n",
      "Epoch 112/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0475 - acc0: 0.3650 - acc1: 0.6891 - acc2: 0.8782 - val_loss: 0.0440 - val_acc0: 0.3946 - val_acc1: 0.7172 - val_acc2: 0.8998\n",
      "Epoch 113/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0475 - acc0: 0.3627 - acc1: 0.6923 - acc2: 0.8769 - val_loss: 0.0440 - val_acc0: 0.3942 - val_acc1: 0.7177 - val_acc2: 0.9005\n",
      "Epoch 114/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0473 - acc0: 0.3637 - acc1: 0.6939 - acc2: 0.8795 - val_loss: 0.0440 - val_acc0: 0.3985 - val_acc1: 0.7167 - val_acc2: 0.8998\n",
      "Epoch 115/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0475 - acc0: 0.3610 - acc1: 0.6900 - acc2: 0.8792 - val_loss: 0.0439 - val_acc0: 0.3975 - val_acc1: 0.7180 - val_acc2: 0.9005\n",
      "Epoch 116/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0476 - acc0: 0.3630 - acc1: 0.6873 - acc2: 0.8789 - val_loss: 0.0439 - val_acc0: 0.3972 - val_acc1: 0.7191 - val_acc2: 0.9006\n",
      "Epoch 117/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0475 - acc0: 0.3641 - acc1: 0.6898 - acc2: 0.8789 - val_loss: 0.0438 - val_acc0: 0.3966 - val_acc1: 0.7183 - val_acc2: 0.8995\n",
      "Epoch 118/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0472 - acc0: 0.3656 - acc1: 0.6914 - acc2: 0.8796 - val_loss: 0.0439 - val_acc0: 0.3966 - val_acc1: 0.7183 - val_acc2: 0.9005\n",
      "Epoch 119/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0474 - acc0: 0.3620 - acc1: 0.6910 - acc2: 0.8802 - val_loss: 0.0438 - val_acc0: 0.3961 - val_acc1: 0.7196 - val_acc2: 0.9006\n",
      "Epoch 120/300\n",
      "388/388 [==============================] - 1s 4ms/step - loss: 0.0475 - acc0: 0.3664 - acc1: 0.6873 - acc2: 0.8786 - val_loss: 0.0438 - val_acc0: 0.3967 - val_acc1: 0.7197 - val_acc2: 0.8998\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0475 - acc0: 0.3619 - acc1: 0.6913 - acc2: 0.8798 - val_loss: 0.0438 - val_acc0: 0.3963 - val_acc1: 0.7183 - val_acc2: 0.9001\n",
      "Epoch 122/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0472 - acc0: 0.3653 - acc1: 0.6916 - acc2: 0.8799 - val_loss: 0.0438 - val_acc0: 0.3969 - val_acc1: 0.7194 - val_acc2: 0.9001\n",
      "Epoch 123/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 0.0474 - acc0: 0.3653 - acc1: 0.6900 - acc2: 0.8806 - val_loss: 0.0437 - val_acc0: 0.3971 - val_acc1: 0.7188 - val_acc2: 0.9003\n",
      "Epoch 124/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0475 - acc0: 0.3637 - acc1: 0.6923 - acc2: 0.8779 - val_loss: 0.0437 - val_acc0: 0.3967 - val_acc1: 0.7189 - val_acc2: 0.9005\n",
      "Epoch 125/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0471 - acc0: 0.3678 - acc1: 0.6943 - acc2: 0.8815 - val_loss: 0.0436 - val_acc0: 0.3975 - val_acc1: 0.7202 - val_acc2: 0.9003\n",
      "Epoch 126/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0473 - acc0: 0.3602 - acc1: 0.6949 - acc2: 0.8790 - val_loss: 0.0436 - val_acc0: 0.3984 - val_acc1: 0.7196 - val_acc2: 0.9006\n",
      "Epoch 127/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0471 - acc0: 0.3637 - acc1: 0.6909 - acc2: 0.8798 - val_loss: 0.0436 - val_acc0: 0.3974 - val_acc1: 0.7194 - val_acc2: 0.9006\n",
      "Epoch 128/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0472 - acc0: 0.3618 - acc1: 0.6914 - acc2: 0.8811 - val_loss: 0.0436 - val_acc0: 0.3972 - val_acc1: 0.7199 - val_acc2: 0.9013\n",
      "Epoch 129/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0472 - acc0: 0.3627 - acc1: 0.6927 - acc2: 0.8784 - val_loss: 0.0436 - val_acc0: 0.3982 - val_acc1: 0.7196 - val_acc2: 0.9014\n",
      "Epoch 130/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0469 - acc0: 0.3689 - acc1: 0.6950 - acc2: 0.8823 - val_loss: 0.0435 - val_acc0: 0.3979 - val_acc1: 0.7197 - val_acc2: 0.9011\n",
      "Epoch 131/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0469 - acc0: 0.3647 - acc1: 0.6925 - acc2: 0.8827 - val_loss: 0.0436 - val_acc0: 0.3982 - val_acc1: 0.7204 - val_acc2: 0.9005\n",
      "Epoch 132/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0471 - acc0: 0.3614 - acc1: 0.6928 - acc2: 0.8794 - val_loss: 0.0435 - val_acc0: 0.3961 - val_acc1: 0.7209 - val_acc2: 0.9013\n",
      "Epoch 133/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0472 - acc0: 0.3665 - acc1: 0.6918 - acc2: 0.8812 - val_loss: 0.0435 - val_acc0: 0.3972 - val_acc1: 0.7231 - val_acc2: 0.9011\n",
      "Epoch 134/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0472 - acc0: 0.3630 - acc1: 0.6930 - acc2: 0.8785 - val_loss: 0.0435 - val_acc0: 0.3974 - val_acc1: 0.7222 - val_acc2: 0.9014\n",
      "Epoch 135/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0472 - acc0: 0.3632 - acc1: 0.6906 - acc2: 0.8804 - val_loss: 0.0435 - val_acc0: 0.3964 - val_acc1: 0.7222 - val_acc2: 0.9013\n",
      "Epoch 136/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0472 - acc0: 0.3653 - acc1: 0.6924 - acc2: 0.8790 - val_loss: 0.0435 - val_acc0: 0.3964 - val_acc1: 0.7235 - val_acc2: 0.9011\n",
      "Epoch 137/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0472 - acc0: 0.3618 - acc1: 0.6933 - acc2: 0.8784 - val_loss: 0.0434 - val_acc0: 0.3966 - val_acc1: 0.7247 - val_acc2: 0.9016\n",
      "Epoch 138/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0473 - acc0: 0.3616 - acc1: 0.6925 - acc2: 0.8789 - val_loss: 0.0434 - val_acc0: 0.3977 - val_acc1: 0.7227 - val_acc2: 0.9013\n",
      "Epoch 139/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0470 - acc0: 0.3656 - acc1: 0.6895 - acc2: 0.8808 - val_loss: 0.0434 - val_acc0: 0.3979 - val_acc1: 0.7225 - val_acc2: 0.9016\n",
      "Epoch 140/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0470 - acc0: 0.3644 - acc1: 0.6933 - acc2: 0.8812 - val_loss: 0.0434 - val_acc0: 0.3977 - val_acc1: 0.7218 - val_acc2: 0.9011\n",
      "Epoch 141/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0471 - acc0: 0.3634 - acc1: 0.6915 - acc2: 0.8802 - val_loss: 0.0434 - val_acc0: 0.3995 - val_acc1: 0.7214 - val_acc2: 0.9003\n",
      "Epoch 142/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0470 - acc0: 0.3631 - acc1: 0.6944 - acc2: 0.8832 - val_loss: 0.0434 - val_acc0: 0.4000 - val_acc1: 0.7228 - val_acc2: 0.9017\n",
      "Epoch 143/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0470 - acc0: 0.3647 - acc1: 0.6920 - acc2: 0.8800 - val_loss: 0.0434 - val_acc0: 0.3998 - val_acc1: 0.7215 - val_acc2: 0.9013\n",
      "Epoch 144/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0470 - acc0: 0.3660 - acc1: 0.6948 - acc2: 0.8819 - val_loss: 0.0434 - val_acc0: 0.3988 - val_acc1: 0.7214 - val_acc2: 0.9014\n",
      "Epoch 145/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0469 - acc0: 0.3642 - acc1: 0.6954 - acc2: 0.8828 - val_loss: 0.0434 - val_acc0: 0.3979 - val_acc1: 0.7220 - val_acc2: 0.9009\n",
      "Epoch 146/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0468 - acc0: 0.3685 - acc1: 0.6951 - acc2: 0.8818 - val_loss: 0.0433 - val_acc0: 0.3987 - val_acc1: 0.7233 - val_acc2: 0.9019\n",
      "Epoch 147/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0468 - acc0: 0.3647 - acc1: 0.6936 - acc2: 0.8833 - val_loss: 0.0433 - val_acc0: 0.4000 - val_acc1: 0.7223 - val_acc2: 0.9017\n",
      "Epoch 148/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0468 - acc0: 0.3668 - acc1: 0.6940 - acc2: 0.8829 - val_loss: 0.0433 - val_acc0: 0.4003 - val_acc1: 0.7230 - val_acc2: 0.9022\n",
      "Epoch 149/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0470 - acc0: 0.3669 - acc1: 0.6943 - acc2: 0.8838 - val_loss: 0.0433 - val_acc0: 0.4019 - val_acc1: 0.7222 - val_acc2: 0.9009\n",
      "Epoch 150/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0469 - acc0: 0.3665 - acc1: 0.6970 - acc2: 0.8823 - val_loss: 0.0433 - val_acc0: 0.4006 - val_acc1: 0.7228 - val_acc2: 0.9019\n",
      "Epoch 151/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0468 - acc0: 0.3709 - acc1: 0.6955 - acc2: 0.8812 - val_loss: 0.0433 - val_acc0: 0.3969 - val_acc1: 0.7243 - val_acc2: 0.9032\n",
      "Epoch 152/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0468 - acc0: 0.3687 - acc1: 0.6968 - acc2: 0.8827 - val_loss: 0.0432 - val_acc0: 0.3975 - val_acc1: 0.7223 - val_acc2: 0.9021\n",
      "Epoch 153/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0468 - acc0: 0.3677 - acc1: 0.6979 - acc2: 0.8818 - val_loss: 0.0432 - val_acc0: 0.3988 - val_acc1: 0.7231 - val_acc2: 0.9025\n",
      "Epoch 154/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0470 - acc0: 0.3665 - acc1: 0.6940 - acc2: 0.8792 - val_loss: 0.0432 - val_acc0: 0.3972 - val_acc1: 0.7236 - val_acc2: 0.9034\n",
      "Epoch 155/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0470 - acc0: 0.3649 - acc1: 0.6969 - acc2: 0.8808 - val_loss: 0.0433 - val_acc0: 0.4011 - val_acc1: 0.7247 - val_acc2: 0.9034\n",
      "Epoch 156/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0468 - acc0: 0.3674 - acc1: 0.6946 - acc2: 0.8841 - val_loss: 0.0432 - val_acc0: 0.4001 - val_acc1: 0.7238 - val_acc2: 0.9035\n",
      "Epoch 157/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0468 - acc0: 0.3665 - acc1: 0.6939 - acc2: 0.8817 - val_loss: 0.0432 - val_acc0: 0.3995 - val_acc1: 0.7243 - val_acc2: 0.9040\n",
      "Epoch 158/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0469 - acc0: 0.3622 - acc1: 0.6958 - acc2: 0.8807 - val_loss: 0.0432 - val_acc0: 0.3988 - val_acc1: 0.7244 - val_acc2: 0.9035\n",
      "Epoch 159/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0466 - acc0: 0.3668 - acc1: 0.6954 - acc2: 0.8844 - val_loss: 0.0432 - val_acc0: 0.4001 - val_acc1: 0.7243 - val_acc2: 0.9034\n",
      "Epoch 160/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0467 - acc0: 0.3706 - acc1: 0.6963 - acc2: 0.8830 - val_loss: 0.0432 - val_acc0: 0.4011 - val_acc1: 0.7231 - val_acc2: 0.9040\n",
      "Epoch 161/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0467 - acc0: 0.3665 - acc1: 0.6956 - acc2: 0.8819 - val_loss: 0.0431 - val_acc0: 0.3972 - val_acc1: 0.7241 - val_acc2: 0.9035\n",
      "Epoch 162/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0467 - acc0: 0.3667 - acc1: 0.6987 - acc2: 0.8831 - val_loss: 0.0432 - val_acc0: 0.3985 - val_acc1: 0.7247 - val_acc2: 0.9038\n",
      "Epoch 163/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0467 - acc0: 0.3625 - acc1: 0.6976 - acc2: 0.8826 - val_loss: 0.0432 - val_acc0: 0.4025 - val_acc1: 0.7244 - val_acc2: 0.9027\n",
      "Epoch 164/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0466 - acc0: 0.3672 - acc1: 0.6966 - acc2: 0.8836 - val_loss: 0.0431 - val_acc0: 0.3975 - val_acc1: 0.7241 - val_acc2: 0.9035\n",
      "Epoch 165/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3644 - acc1: 0.6948 - acc2: 0.8844 - val_loss: 0.0431 - val_acc0: 0.3988 - val_acc1: 0.7259 - val_acc2: 0.9035\n",
      "Epoch 166/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0466 - acc0: 0.3651 - acc1: 0.6967 - acc2: 0.8826 - val_loss: 0.0431 - val_acc0: 0.3992 - val_acc1: 0.7256 - val_acc2: 0.9034\n",
      "Epoch 167/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0467 - acc0: 0.3693 - acc1: 0.6970 - acc2: 0.8839 - val_loss: 0.0431 - val_acc0: 0.3998 - val_acc1: 0.7247 - val_acc2: 0.9029\n",
      "Epoch 168/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0467 - acc0: 0.3680 - acc1: 0.6957 - acc2: 0.8829 - val_loss: 0.0431 - val_acc0: 0.3998 - val_acc1: 0.7254 - val_acc2: 0.9025\n",
      "Epoch 169/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0468 - acc0: 0.3667 - acc1: 0.6960 - acc2: 0.8825 - val_loss: 0.0431 - val_acc0: 0.3990 - val_acc1: 0.7241 - val_acc2: 0.9024\n",
      "Epoch 170/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0467 - acc0: 0.3651 - acc1: 0.6970 - acc2: 0.8833 - val_loss: 0.0431 - val_acc0: 0.3992 - val_acc1: 0.7254 - val_acc2: 0.9027\n",
      "Epoch 171/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3706 - acc1: 0.6976 - acc2: 0.8840 - val_loss: 0.0431 - val_acc0: 0.3995 - val_acc1: 0.7247 - val_acc2: 0.9027\n",
      "Epoch 172/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0468 - acc0: 0.3674 - acc1: 0.6952 - acc2: 0.8820 - val_loss: 0.0431 - val_acc0: 0.3985 - val_acc1: 0.7257 - val_acc2: 0.9022\n",
      "Epoch 173/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0464 - acc0: 0.3689 - acc1: 0.6997 - acc2: 0.8845 - val_loss: 0.0431 - val_acc0: 0.3987 - val_acc1: 0.7251 - val_acc2: 0.9025\n",
      "Epoch 174/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0467 - acc0: 0.3629 - acc1: 0.6958 - acc2: 0.8827 - val_loss: 0.0431 - val_acc0: 0.3987 - val_acc1: 0.7243 - val_acc2: 0.9025\n",
      "Epoch 175/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3685 - acc1: 0.6987 - acc2: 0.8846 - val_loss: 0.0431 - val_acc0: 0.3990 - val_acc1: 0.7254 - val_acc2: 0.9025\n",
      "Epoch 176/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3668 - acc1: 0.7016 - acc2: 0.8853 - val_loss: 0.0430 - val_acc0: 0.3984 - val_acc1: 0.7256 - val_acc2: 0.9024\n",
      "Epoch 177/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3682 - acc1: 0.6979 - acc2: 0.8848 - val_loss: 0.0430 - val_acc0: 0.3979 - val_acc1: 0.7243 - val_acc2: 0.9024\n",
      "Epoch 178/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0466 - acc0: 0.3678 - acc1: 0.6968 - acc2: 0.8819 - val_loss: 0.0430 - val_acc0: 0.4013 - val_acc1: 0.7251 - val_acc2: 0.9024\n",
      "Epoch 179/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3707 - acc1: 0.6948 - acc2: 0.8846 - val_loss: 0.0430 - val_acc0: 0.3992 - val_acc1: 0.7262 - val_acc2: 0.9029\n",
      "Epoch 180/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3648 - acc1: 0.6971 - acc2: 0.8842 - val_loss: 0.0430 - val_acc0: 0.4000 - val_acc1: 0.7254 - val_acc2: 0.9027\n",
      "Epoch 181/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0466 - acc0: 0.3686 - acc1: 0.7000 - acc2: 0.8842 - val_loss: 0.0430 - val_acc0: 0.3998 - val_acc1: 0.7246 - val_acc2: 0.9019\n",
      "Epoch 182/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3701 - acc1: 0.6996 - acc2: 0.8812 - val_loss: 0.0430 - val_acc0: 0.4005 - val_acc1: 0.7247 - val_acc2: 0.9021\n",
      "Epoch 183/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0463 - acc0: 0.3642 - acc1: 0.7004 - acc2: 0.8866 - val_loss: 0.0430 - val_acc0: 0.4009 - val_acc1: 0.7239 - val_acc2: 0.9027\n",
      "Epoch 184/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0463 - acc0: 0.3687 - acc1: 0.7015 - acc2: 0.8865 - val_loss: 0.0430 - val_acc0: 0.4008 - val_acc1: 0.7251 - val_acc2: 0.9024\n",
      "Epoch 185/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0463 - acc0: 0.3693 - acc1: 0.7028 - acc2: 0.8845 - val_loss: 0.0430 - val_acc0: 0.3996 - val_acc1: 0.7257 - val_acc2: 0.9025\n",
      "Epoch 186/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0464 - acc0: 0.3666 - acc1: 0.6980 - acc2: 0.8845 - val_loss: 0.0430 - val_acc0: 0.3993 - val_acc1: 0.7251 - val_acc2: 0.9029\n",
      "Epoch 187/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0464 - acc0: 0.3683 - acc1: 0.6974 - acc2: 0.8852 - val_loss: 0.0430 - val_acc0: 0.3977 - val_acc1: 0.7241 - val_acc2: 0.9021\n",
      "Epoch 188/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0464 - acc0: 0.3666 - acc1: 0.6995 - acc2: 0.8857 - val_loss: 0.0430 - val_acc0: 0.3985 - val_acc1: 0.7244 - val_acc2: 0.9029\n",
      "Epoch 189/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0461 - acc0: 0.3688 - acc1: 0.7000 - acc2: 0.8868 - val_loss: 0.0430 - val_acc0: 0.3988 - val_acc1: 0.7267 - val_acc2: 0.9032\n",
      "Epoch 190/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0467 - acc0: 0.3637 - acc1: 0.6976 - acc2: 0.8833 - val_loss: 0.0430 - val_acc0: 0.3982 - val_acc1: 0.7265 - val_acc2: 0.9037\n",
      "Epoch 191/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0463 - acc0: 0.3683 - acc1: 0.7023 - acc2: 0.8843 - val_loss: 0.0430 - val_acc0: 0.3982 - val_acc1: 0.7257 - val_acc2: 0.9030\n",
      "Epoch 192/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3699 - acc1: 0.6999 - acc2: 0.8837 - val_loss: 0.0430 - val_acc0: 0.3975 - val_acc1: 0.7268 - val_acc2: 0.9040\n",
      "Epoch 193/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3657 - acc1: 0.6965 - acc2: 0.8853 - val_loss: 0.0429 - val_acc0: 0.3979 - val_acc1: 0.7257 - val_acc2: 0.9032\n",
      "Epoch 194/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0464 - acc0: 0.3697 - acc1: 0.6972 - acc2: 0.8836 - val_loss: 0.0430 - val_acc0: 0.3982 - val_acc1: 0.7260 - val_acc2: 0.9030\n",
      "Epoch 195/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0463 - acc0: 0.3679 - acc1: 0.7006 - acc2: 0.8873 - val_loss: 0.0429 - val_acc0: 0.3985 - val_acc1: 0.7254 - val_acc2: 0.9034\n",
      "Epoch 196/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3668 - acc1: 0.7016 - acc2: 0.8842 - val_loss: 0.0430 - val_acc0: 0.3993 - val_acc1: 0.7239 - val_acc2: 0.9034\n",
      "Epoch 197/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0464 - acc0: 0.3680 - acc1: 0.6979 - acc2: 0.8848 - val_loss: 0.0430 - val_acc0: 0.3985 - val_acc1: 0.7251 - val_acc2: 0.9040\n",
      "Epoch 198/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0463 - acc0: 0.3691 - acc1: 0.7011 - acc2: 0.8841 - val_loss: 0.0429 - val_acc0: 0.3979 - val_acc1: 0.7260 - val_acc2: 0.9034\n",
      "Epoch 199/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0465 - acc0: 0.3686 - acc1: 0.6988 - acc2: 0.8829 - val_loss: 0.0429 - val_acc0: 0.3964 - val_acc1: 0.7251 - val_acc2: 0.9040\n",
      "Epoch 200/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0462 - acc0: 0.3710 - acc1: 0.7014 - acc2: 0.8863 - val_loss: 0.0429 - val_acc0: 0.3974 - val_acc1: 0.7256 - val_acc2: 0.9037\n",
      "Epoch 201/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0466 - acc0: 0.3623 - acc1: 0.6981 - acc2: 0.8840 - val_loss: 0.0430 - val_acc0: 0.3990 - val_acc1: 0.7247 - val_acc2: 0.9032\n",
      "Epoch 202/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 0.0463 - acc0: 0.3726 - acc1: 0.6968 - acc2: 0.8863 - val_loss: 0.0429 - val_acc0: 0.3987 - val_acc1: 0.7257 - val_acc2: 0.9037\n",
      "Epoch 00202: early stopping\n"
     ]
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=4, verbose=1)]\n",
    "batch_size = 64\n",
    "max_epochs = 300\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, validation_data=(x_test, y_test), epochs=max_epochs, callbacks=callbacks)\n",
    "\n",
    "# [256, 128, 64], p=.4, flattened, 28e\n",
    "# loss: 0.0396 - acc0: 0.4144 - acc1: 0.7597 - acc2: 0.9229 - val_loss: 0.0414 - val_acc0: 0.3925 - val_acc1: 0.7375 - val_acc2: 0.9140\n",
    "\n",
    "# [16, 16], p=.4, flattened, 76e\n",
    "# loss: 0.0446 - acc0: 0.3766 - acc1: 0.7139 - acc2: 0.8944 - val_loss: 0.0416 - val_acc0: 0.3879 - val_acc1: 0.7438 - val_acc2: 0.9138\n",
    "\n",
    "# [16, 16], p=.4, flattened, lr 1e-4, 202e\n",
    "# loss: 0.0463 - acc0: 0.3726 - acc1: 0.6968 - acc2: 0.8863 - val_loss: 0.0429 - val_acc0: 0.3987 - val_acc1: 0.7257 - val_acc2: 0.9037\n",
    "\n",
    "# [32], p=.4, flattened, 31e\n",
    "# loss: 0.0431 - acc0: 0.3896 - acc1: 0.7303 - acc2: 0.9021 - val_loss: 0.0416 - val_acc0: 0.4055 - val_acc1: 0.7385 - val_acc2: 0.9096\n",
    "\n",
    "# [256, 128, 64], p=.4, 3d, 24e\n",
    "# loss: 0.0409 - acc0: 0.4075 - acc1: 0.7475 - acc2: 0.9123 - val_loss: 0.0421 - val_acc0: 0.3945 - val_acc1: 0.7389 - val_acc2: 0.9076\n",
    "\n",
    "# [64, 64], p=.4, 3d, 32e\n",
    "# loss: 0.0420 - acc0: 0.4018 - acc1: 0.7372 - acc2: 0.9087 - val_loss: 0.0419 - val_acc0: 0.3992 - val_acc1: 0.7396 - val_acc2: 0.9080\n",
    "\n",
    "# [64], p=.4, 3d, 44e\n",
    "# loss: 0.0405 - acc0: 0.4103 - acc1: 0.7505 - acc2: 0.9152 - val_loss: 0.0416 - val_acc0: 0.4016 - val_acc1: 0.7402 - val_acc2: 0.9092\n",
    "\n",
    "# [32], p=.4, 3d, 59e\n",
    "# loss: 0.0418 - acc0: 0.4037 - acc1: 0.7396 - acc2: 0.9084 - val_loss: 0.0420 - val_acc0: 0.4045 - val_acc1: 0.7314 - val_acc2: 0.9093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.round(model.predict(x_test[99][np.newaxis, :]) * 100))\n",
    "# print(y_test[99])\n",
    "y_true = y_test[[2, 4, 8, 16, 32]]\n",
    "y_pred = model.predict(x_test[[2, 4, 8, 16, 32]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]], shape=(5, 17), dtype=int8) tf.Tensor(\n",
      "[[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]], shape=(5, 17), dtype=int8)\n",
      "tf.Tensor([7 8 7 8 6], shape=(5,), dtype=int64) tf.Tensor([8 9 6 7 6], shape=(5,), dtype=int64)\n",
      "tf.Tensor([False False False False  True], shape=(5,), dtype=bool) tf.Tensor(1.0, shape=(), dtype=float32) tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred_thresh = tf.cast(y_pred >= .5, 'int8')\n",
    "true_thresh = tf.cast(y_true >= .5, 'int8')\n",
    "print(pred_thresh, true_thresh)\n",
    "\n",
    "# Since tf.argmin returns the lowest index possible, this gets us the index of the last True value.\n",
    "# Note that this is -1 if the network doesn't many any prediction at all.\n",
    "pred_idx = tf.argmin(pred_thresh, axis=-1) - 1\n",
    "true_idx = tf.argmin(true_thresh, axis=-1) - 1\n",
    "print(pred_idx, true_idx)\n",
    "\n",
    "distance_bools = tf.abs(pred_idx - true_idx) <= 0\n",
    "correct = tf.reduce_sum(tf.cast(distance_bools, 'float32'))\n",
    "incorrect = tf.reduce_sum(tf.cast(tf.logical_not(distance_bools), 'float32'))\n",
    "print(distance_bools, correct, incorrect)\n",
    "\n",
    "print(correct / (correct+incorrect))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('venv': venv)",
   "language": "python",
   "name": "python38264bitvenvvenv62f2ef13a99a49ca88eefe3bb4a02605"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
