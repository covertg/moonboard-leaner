{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moon.data\n",
    "import moon.problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = moon.data.read_problems('data/cleaned_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30991, 18, 11) (30991, 17)\n",
      "((24793, 18, 11), (24793, 17)) ((6198, 18, 11), (6198, 17))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([p.array for p in probs])\n",
    "y = np.array([p.grade.onehot for p in probs])\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "split = 0.2\n",
    "indices = np.arange(len(probs))\n",
    "np.random.shuffle(indices)\n",
    "n_test = int(len(probs) * split)\n",
    "\n",
    "x_train, y_train = x[indices[n_test:]], y[indices[n_test:]]\n",
    "x_test, y_test = x[indices[0:n_test]], y[indices[0:n_test]]\n",
    "print((x_train.shape, y_train.shape), (x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "# Metric to compute \"accuracy within k\" ordinal classes, if the output is independent sigmoids.\n",
    "# See section 2.3: http://calla.rnet.missouri.edu/cheng_courses/rank.pdf\n",
    "# Written but no longer used; instead we use a weighted cross-entropy for loss and softmax (one-hot) for output.\n",
    "class OrdinalAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='acc_within_k', k=0, threshold=0.5, **kwargs):\n",
    "        super(OrdinalAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "        self.total = self.add_weight(name='total', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        pred_thresh = tf.cast(y_pred >= self.threshold, 'int8')\n",
    "        true_thresh = tf.cast(y_true >= self.threshold, 'int8')\n",
    "        # Since tf.argmin returns the lowest index possible, this gets us the index of the last True value.\n",
    "        # Note that this is -1 if the network doesn't many any prediction at all.\n",
    "        pred_idx = tf.argmin(pred_thresh, axis=-1) - 1\n",
    "        true_idx = tf.argmin(true_thresh, axis=-1) - 1\n",
    "        distance_bools = (tf.abs(pred_idx - true_idx) <= self.k)\n",
    "        correct = tf.reduce_sum(tf.cast(distance_bools, 'float32'))\n",
    "        incorrect = tf.reduce_sum(tf.cast(tf.logical_not(distance_bools), 'float32'))\n",
    "        self.total.assign_add(correct)\n",
    "        self.count.assign_add(correct + incorrect)\n",
    "    \n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "\n",
    "# Metric to compute \"accuracy within k\" ordinal classes, if the output is softmax.\n",
    "class OrdinalAccuracySoftmax(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='acc_within_k', k=0, **kwargs):\n",
    "        super(OrdinalAccuracySoftmax, self).__init__(name=name, **kwargs)\n",
    "        self.k = k\n",
    "        self.correct = self.add_weight(name='correct', initializer='zeros')\n",
    "        self.incorrect = self.add_weight(name='incorrect', initializer='zeros')\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        pred_idx = tf.argmax(y_pred, axis=-1)\n",
    "        true_idx = tf.argmax(y_true, axis=-1)\n",
    "        distance_bools = (tf.abs(pred_idx - true_idx) <= self.k)\n",
    "        correct = tf.reduce_sum(tf.cast(distance_bools, 'float32'))\n",
    "        incorrect = tf.reduce_sum(tf.cast(tf.logical_not(distance_bools), 'float32'))\n",
    "        self.correct.assign_add(correct)\n",
    "        self.incorrect.assign_add(incorrect)     \n",
    "    \n",
    "    def result(self):\n",
    "        return self.correct / (self.correct + self.incorrect)\n",
    "\n",
    "\n",
    "# https://github.com/JHart96/keras_ordinal_categorical_crossentropy GPLv3 license\n",
    "def ordinal_categorical_crossentropy_loss(y_true, y_pred):\n",
    "    weights = K.cast(K.abs(K.argmax(y_true, axis=1) - K.argmax(y_pred, axis=1))/(K.int_shape(y_pred)[1] - 1), dtype='float32')\n",
    "    return (1.0 + weights) * tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "# see\n",
    "# https://arxiv.org/abs/1901.07884 and https://github.com/Raschka-research-group/coral-cnn/issues/9\n",
    "# more background https://arxiv.org/abs/1705.05278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# α = 0.3\n",
    "p = .4\n",
    "input_shape = moon.problem.Problem.GRID_SHAPE\n",
    "hiddens = [16, 16]\n",
    "hidden_activation = 'swish'\n",
    "output_shape = moon.problem.Grade.N_GRADES\n",
    "output_activation = 'softmax'\n",
    "\n",
    "metrics = [OrdinalAccuracySoftmax(name='acc0', k=0), OrdinalAccuracySoftmax(name='acc1', k=1), OrdinalAccuracySoftmax(name='acc2', k=2)]\n",
    "loss = ordinal_categorical_crossentropy_loss\n",
    "# loss = 'categorical_crossentropy'\n",
    "adam_lr = 1e-3\n",
    "optim = tf.keras.optimizers.Adam(lr=adam_lr)\n",
    "\n",
    "in_x = layers.Input(shape=input_shape)\n",
    "features = layers.Flatten()(in_x)\n",
    "for nodes in hiddens:\n",
    "    features = layers.Dense(nodes, activation=hidden_activation)(features)\n",
    "    # features = layers.ReLU(α)(features)\n",
    "    if p > 0: features = layers.Dropout(p)(features)\n",
    "out_y = layers.Dense(output_shape, activation=output_activation)(features)\n",
    "\n",
    "model = tf.keras.Model(in_x, out_y, name='Feedforward_classifier')\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 2.4705 - acc0: 0.3091 - acc1: 0.4770 - acc2: 0.6432 - val_loss: 1.9506 - val_acc0: 0.3675 - val_acc1: 0.5544 - val_acc2: 0.7191\n",
      "Epoch 2/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.9909 - acc0: 0.3646 - acc1: 0.5730 - acc2: 0.7456 - val_loss: 1.8308 - val_acc0: 0.3871 - val_acc1: 0.6086 - val_acc2: 0.7815\n",
      "Epoch 3/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.9195 - acc0: 0.3734 - acc1: 0.5966 - acc2: 0.7698 - val_loss: 1.7903 - val_acc0: 0.3922 - val_acc1: 0.6273 - val_acc2: 0.7959\n",
      "Epoch 4/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.8709 - acc0: 0.3800 - acc1: 0.6040 - acc2: 0.7845 - val_loss: 1.7623 - val_acc0: 0.3985 - val_acc1: 0.6397 - val_acc2: 0.8098\n",
      "Epoch 5/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.8487 - acc0: 0.3838 - acc1: 0.6163 - acc2: 0.7955 - val_loss: 1.7495 - val_acc0: 0.4008 - val_acc1: 0.6434 - val_acc2: 0.8146\n",
      "Epoch 6/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.8322 - acc0: 0.3864 - acc1: 0.6184 - acc2: 0.7982 - val_loss: 1.7397 - val_acc0: 0.3990 - val_acc1: 0.6434 - val_acc2: 0.8136\n",
      "Epoch 7/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.8148 - acc0: 0.3910 - acc1: 0.6273 - acc2: 0.8061 - val_loss: 1.7317 - val_acc0: 0.4042 - val_acc1: 0.6554 - val_acc2: 0.8282\n",
      "Epoch 8/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.8081 - acc0: 0.3907 - acc1: 0.6280 - acc2: 0.8068 - val_loss: 1.7293 - val_acc0: 0.4009 - val_acc1: 0.6505 - val_acc2: 0.8228\n",
      "Epoch 9/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7992 - acc0: 0.3917 - acc1: 0.6293 - acc2: 0.8090 - val_loss: 1.7213 - val_acc0: 0.4046 - val_acc1: 0.6563 - val_acc2: 0.8356\n",
      "Epoch 10/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7958 - acc0: 0.3930 - acc1: 0.6327 - acc2: 0.8141 - val_loss: 1.7176 - val_acc0: 0.4067 - val_acc1: 0.6580 - val_acc2: 0.8333\n",
      "Epoch 11/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7882 - acc0: 0.3955 - acc1: 0.6347 - acc2: 0.8124 - val_loss: 1.7117 - val_acc0: 0.4058 - val_acc1: 0.6602 - val_acc2: 0.8412\n",
      "Epoch 12/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7862 - acc0: 0.3964 - acc1: 0.6349 - acc2: 0.8147 - val_loss: 1.7105 - val_acc0: 0.4050 - val_acc1: 0.6541 - val_acc2: 0.8293\n",
      "Epoch 13/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7784 - acc0: 0.3977 - acc1: 0.6400 - acc2: 0.8182 - val_loss: 1.7045 - val_acc0: 0.4096 - val_acc1: 0.6651 - val_acc2: 0.8420\n",
      "Epoch 14/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7743 - acc0: 0.3995 - acc1: 0.6424 - acc2: 0.8217 - val_loss: 1.7020 - val_acc0: 0.4085 - val_acc1: 0.6581 - val_acc2: 0.8309\n",
      "Epoch 15/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7713 - acc0: 0.3979 - acc1: 0.6391 - acc2: 0.8193 - val_loss: 1.6955 - val_acc0: 0.4135 - val_acc1: 0.6660 - val_acc2: 0.8390\n",
      "Epoch 16/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7692 - acc0: 0.3982 - acc1: 0.6418 - acc2: 0.8226 - val_loss: 1.6930 - val_acc0: 0.4098 - val_acc1: 0.6676 - val_acc2: 0.8448\n",
      "Epoch 17/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7674 - acc0: 0.3961 - acc1: 0.6415 - acc2: 0.8217 - val_loss: 1.6905 - val_acc0: 0.4082 - val_acc1: 0.6625 - val_acc2: 0.8353\n",
      "Epoch 18/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7601 - acc0: 0.4010 - acc1: 0.6470 - acc2: 0.8235 - val_loss: 1.6861 - val_acc0: 0.4134 - val_acc1: 0.6689 - val_acc2: 0.8433\n",
      "Epoch 19/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7587 - acc0: 0.3993 - acc1: 0.6456 - acc2: 0.8266 - val_loss: 1.6840 - val_acc0: 0.4122 - val_acc1: 0.6684 - val_acc2: 0.8403\n",
      "Epoch 20/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7547 - acc0: 0.4001 - acc1: 0.6465 - acc2: 0.8240 - val_loss: 1.6780 - val_acc0: 0.4164 - val_acc1: 0.6726 - val_acc2: 0.8483\n",
      "Epoch 21/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7503 - acc0: 0.4029 - acc1: 0.6459 - acc2: 0.8306 - val_loss: 1.6801 - val_acc0: 0.4132 - val_acc1: 0.6662 - val_acc2: 0.8366\n",
      "Epoch 22/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7483 - acc0: 0.3998 - acc1: 0.6464 - acc2: 0.8258 - val_loss: 1.6748 - val_acc0: 0.4132 - val_acc1: 0.6702 - val_acc2: 0.8433\n",
      "Epoch 23/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7464 - acc0: 0.4023 - acc1: 0.6492 - acc2: 0.8333 - val_loss: 1.6729 - val_acc0: 0.4158 - val_acc1: 0.6746 - val_acc2: 0.8533\n",
      "Epoch 24/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7439 - acc0: 0.4018 - acc1: 0.6512 - acc2: 0.8282 - val_loss: 1.6694 - val_acc0: 0.4155 - val_acc1: 0.6770 - val_acc2: 0.8530\n",
      "Epoch 25/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7402 - acc0: 0.4050 - acc1: 0.6547 - acc2: 0.8335 - val_loss: 1.6694 - val_acc0: 0.4137 - val_acc1: 0.6715 - val_acc2: 0.8480\n",
      "Epoch 26/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7431 - acc0: 0.4038 - acc1: 0.6518 - acc2: 0.8319 - val_loss: 1.6683 - val_acc0: 0.4159 - val_acc1: 0.6763 - val_acc2: 0.8533\n",
      "Epoch 27/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7361 - acc0: 0.4064 - acc1: 0.6541 - acc2: 0.8321 - val_loss: 1.6655 - val_acc0: 0.4167 - val_acc1: 0.6767 - val_acc2: 0.8506\n",
      "Epoch 28/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7366 - acc0: 0.4049 - acc1: 0.6545 - acc2: 0.8324 - val_loss: 1.6651 - val_acc0: 0.4167 - val_acc1: 0.6742 - val_acc2: 0.8503\n",
      "Epoch 29/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7354 - acc0: 0.4038 - acc1: 0.6562 - acc2: 0.8340 - val_loss: 1.6625 - val_acc0: 0.4185 - val_acc1: 0.6826 - val_acc2: 0.8606\n",
      "Epoch 30/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7348 - acc0: 0.4033 - acc1: 0.6533 - acc2: 0.8396 - val_loss: 1.6626 - val_acc0: 0.4161 - val_acc1: 0.6794 - val_acc2: 0.8564\n",
      "Epoch 31/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7308 - acc0: 0.4076 - acc1: 0.6567 - acc2: 0.8387 - val_loss: 1.6607 - val_acc0: 0.4182 - val_acc1: 0.6817 - val_acc2: 0.8587\n",
      "Epoch 32/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7321 - acc0: 0.4046 - acc1: 0.6563 - acc2: 0.8365 - val_loss: 1.6584 - val_acc0: 0.4193 - val_acc1: 0.6855 - val_acc2: 0.8571\n",
      "Epoch 33/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7283 - acc0: 0.4055 - acc1: 0.6590 - acc2: 0.8398 - val_loss: 1.6607 - val_acc0: 0.4130 - val_acc1: 0.6847 - val_acc2: 0.8621\n",
      "Epoch 34/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7287 - acc0: 0.4025 - acc1: 0.6552 - acc2: 0.8377 - val_loss: 1.6589 - val_acc0: 0.4138 - val_acc1: 0.6773 - val_acc2: 0.8548\n",
      "Epoch 35/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7250 - acc0: 0.4056 - acc1: 0.6618 - acc2: 0.8394 - val_loss: 1.6575 - val_acc0: 0.4198 - val_acc1: 0.6823 - val_acc2: 0.8619\n",
      "Epoch 36/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7267 - acc0: 0.4067 - acc1: 0.6596 - acc2: 0.8370 - val_loss: 1.6555 - val_acc0: 0.4190 - val_acc1: 0.6851 - val_acc2: 0.8624\n",
      "Epoch 37/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7260 - acc0: 0.4069 - acc1: 0.6608 - acc2: 0.8375 - val_loss: 1.6571 - val_acc0: 0.4174 - val_acc1: 0.6776 - val_acc2: 0.8550\n",
      "Epoch 38/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7226 - acc0: 0.4073 - acc1: 0.6560 - acc2: 0.8377 - val_loss: 1.6549 - val_acc0: 0.4190 - val_acc1: 0.6836 - val_acc2: 0.8630\n",
      "Epoch 39/300\n",
      "388/388 [==============================] - 1s 3ms/step - loss: 1.7232 - acc0: 0.4085 - acc1: 0.6625 - acc2: 0.8414 - val_loss: 1.6570 - val_acc0: 0.4184 - val_acc1: 0.6793 - val_acc2: 0.8575\n",
      "Epoch 40/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7208 - acc0: 0.4081 - acc1: 0.6617 - acc2: 0.8380 - val_loss: 1.6565 - val_acc0: 0.4193 - val_acc1: 0.6807 - val_acc2: 0.8553\n",
      "Epoch 41/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7261 - acc0: 0.4081 - acc1: 0.6576 - acc2: 0.8382 - val_loss: 1.6551 - val_acc0: 0.4195 - val_acc1: 0.6859 - val_acc2: 0.8617\n",
      "Epoch 42/300\n",
      "388/388 [==============================] - 1s 2ms/step - loss: 1.7202 - acc0: 0.4096 - acc1: 0.6641 - acc2: 0.8420 - val_loss: 1.6567 - val_acc0: 0.4193 - val_acc1: 0.6813 - val_acc2: 0.8616\n",
      "Epoch 00042: early stopping\n"
     ]
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=4, verbose=1)]\n",
    "batch_size = 64\n",
    "max_epochs = 300\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, validation_data=(x_test, y_test), epochs=max_epochs, callbacks=callbacks)\n",
    "\n",
    "# [256, 128, 64], p=.4, flattened, 28e\n",
    "# loss: 0.0396 - acc0: 0.4144 - acc1: 0.7597 - acc2: 0.9229 - val_loss: 0.0414 - val_acc0: 0.3925 - val_acc1: 0.7375 - val_acc2: 0.9140\n",
    "\n",
    "# [16, 16], p=.4, flattened, 76e\n",
    "# loss: 0.0446 - acc0: 0.3766 - acc1: 0.7139 - acc2: 0.8944 - val_loss: 0.0416 - val_acc0: 0.3879 - val_acc1: 0.7438 - val_acc2: 0.9138\n",
    "\n",
    "# [16, 16], p=.4, flattened, onehots!, 71e, softmax+cce\n",
    "# loss: 1.5533 - acc0: 0.4083 - acc1: 0.6546 - acc2: 0.8327 - val_loss: 1.4997 - val_acc0: 0.4226 - val_acc1: 0.6822 - val_acc2: 0.8567\n",
    "# [16, 16], p=.4, flattened, onehots, 49e, softmax+ordinalcce\n",
    "# loss: 1.7202 - acc0: 0.4096 - acc1: 0.6641 - acc2: 0.8420 - val_loss: 1.6567 - val_acc0: 0.4193 - val_acc1: 0.6813 - val_acc2: 0.8616\n",
    "\n",
    "# [16, 16], p=.4, flattened, lr 1e-4, 202e\n",
    "# loss: 0.0463 - acc0: 0.3726 - acc1: 0.6968 - acc2: 0.8863 - val_loss: 0.0429 - val_acc0: 0.3987 - val_acc1: 0.7257 - val_acc2: 0.9037\n",
    "\n",
    "# [32], p=.4, flattened, 31e\n",
    "# loss: 0.0431 - acc0: 0.3896 - acc1: 0.7303 - acc2: 0.9021 - val_loss: 0.0416 - val_acc0: 0.4055 - val_acc1: 0.7385 - val_acc2: 0.9096\n",
    "\n",
    "# [256, 128, 64], p=.4, 3d, 24e\n",
    "# loss: 0.0409 - acc0: 0.4075 - acc1: 0.7475 - acc2: 0.9123 - val_loss: 0.0421 - val_acc0: 0.3945 - val_acc1: 0.7389 - val_acc2: 0.9076\n",
    "\n",
    "# [64, 64], p=.4, 3d, 32e\n",
    "# loss: 0.0420 - acc0: 0.4018 - acc1: 0.7372 - acc2: 0.9087 - val_loss: 0.0419 - val_acc0: 0.3992 - val_acc1: 0.7396 - val_acc2: 0.9080\n",
    "\n",
    "# [64], p=.4, 3d, 44e\n",
    "# loss: 0.0405 - acc0: 0.4103 - acc1: 0.7505 - acc2: 0.9152 - val_loss: 0.0416 - val_acc0: 0.4016 - val_acc1: 0.7402 - val_acc2: 0.9092\n",
    "\n",
    "# [32], p=.4, 3d, 59e\n",
    "# loss: 0.0418 - acc0: 0.4037 - acc1: 0.7396 - acc2: 0.9084 - val_loss: 0.0420 - val_acc0: 0.4045 - val_acc1: 0.7314 - val_acc2: 0.9093"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.round(model.predict(x_test[99][np.newaxis, :]) * 100))\n",
    "# print(y_test[99])\n",
    "y_true = y_test[[2, 4, 8, 16, 32]]\n",
    "y_pred = model.predict(x_test[[2, 4, 8, 16, 32]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]], shape=(5, 17), dtype=int8) tf.Tensor(\n",
      "[[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]], shape=(5, 17), dtype=int8)\n",
      "tf.Tensor([7 8 7 8 6], shape=(5,), dtype=int64) tf.Tensor([8 9 6 7 6], shape=(5,), dtype=int64)\n",
      "tf.Tensor([False False False False  True], shape=(5,), dtype=bool) tf.Tensor(1.0, shape=(), dtype=float32) tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred_thresh = tf.cast(y_pred >= .5, 'int8')\n",
    "true_thresh = tf.cast(y_true >= .5, 'int8')\n",
    "print(pred_thresh, true_thresh)\n",
    "\n",
    "# Since tf.argmin returns the lowest index possible, this gets us the index of the last True value.\n",
    "# Note that this is -1 if the network doesn't many any prediction at all.\n",
    "pred_idx = tf.argmin(pred_thresh, axis=-1) - 1\n",
    "true_idx = tf.argmin(true_thresh, axis=-1) - 1\n",
    "print(pred_idx, true_idx)\n",
    "\n",
    "distance_bools = tf.abs(pred_idx - true_idx) <= 0\n",
    "correct = tf.reduce_sum(tf.cast(distance_bools, 'float32'))\n",
    "incorrect = tf.reduce_sum(tf.cast(tf.logical_not(distance_bools), 'float32'))\n",
    "print(distance_bools, correct, incorrect)\n",
    "\n",
    "print(correct / (correct+incorrect))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('venv': venv)",
   "language": "python",
   "name": "python38264bitvenvvenv62f2ef13a99a49ca88eefe3bb4a02605"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
