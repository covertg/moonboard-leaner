{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moon.data\n",
    "import moon.problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = moon.data.read_problems('data/cleaned_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30991, 18, 11, 3) (30991, 17)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([p.array_3d for p in probs])\n",
    "y = np.array([p.grade.ordinal for p in probs])\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class OrdinalAccuracy(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='ordinal_acc_within_k', k=0, threshold=0.5, **kwargs):\n",
    "        super(OrdinalAccuracy, self).__init__(name=name, **kwargs)\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "        self.total = self.add_weight(name='total', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # See section 2.3: http://calla.rnet.missouri.edu/cheng_courses/rank.pdf\n",
    "        pred_thresh = tf.cast(y_pred >= self.threshold, 'int8')\n",
    "        true_thresh = tf.cast(y_true >= self.threshold, 'int8')\n",
    "        pred_idx = tf.argmin(pred_thresh, axis=-1) - 1\n",
    "        true_idx = tf.argmin(true_thresh, axis=-1) - 1\n",
    "        distance_bools = (tf.abs(pred_idx - true_idx) <= self.k)\n",
    "        correct = tf.reduce_sum(tf.cast(distance_bools, 'float32'))\n",
    "        incorrect = tf.reduce_sum(tf.cast(tf.logical_not(distance_bools), 'float32'))\n",
    "        self.total.assign_add(correct)\n",
    "        self.count.assign_add(correct + incorrect)\n",
    "    \n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    \n",
    "# α = 0.3\n",
    "p = .4\n",
    "input_shape = (*moon.problem.Problem.GRID_SHAPE, 3)\n",
    "hiddens = [256, 128, 64]\n",
    "hidden_activation = 'swish'\n",
    "output_shape = moon.problem.Grade.N_GRADES\n",
    "output_activation = 'sigmoid'\n",
    "loss = 'mse'\n",
    "adam_lr = 1e-3\n",
    "\n",
    "metrics = [OrdinalAccuracy(name='acc0', k=0), OrdinalAccuracy(name='acc1', k=1), OrdinalAccuracy(name='acc2', k=2)]\n",
    "optim = tf.keras.optimizers.Adam(lr=adam_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_x = layers.Input(shape=input_shape)\n",
    "features = layers.Flatten()(in_x)\n",
    "for nodes in hiddens:\n",
    "    features = layers.Dense(nodes, activation=hidden_activation)(features)\n",
    "    # features = layers.ReLU(α)(features)\n",
    "    if p > 0: features = layers.Dropout(p)(features)\n",
    "out_y = layers.Dense(output_shape, activation=output_activation)(features)\n",
    "\n",
    "model = tf.keras.Model(in_x, out_y, name='Feedforward_classifier')\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24793, 18, 11, 3) (6198, 18, 11, 3)\n"
     ]
    }
   ],
   "source": [
    "split = 0.2\n",
    "indices = np.arange(len(probs))\n",
    "np.random.shuffle(indices)\n",
    "n_test = int(len(probs) * split)\n",
    "\n",
    "x_train, y_train = x[indices[n_test:]], y[indices[n_test:]]\n",
    "x_test, y_test = x[indices[0:n_test]], y[indices[0:n_test]]\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.0670 - acc0: 0.2926 - acc1: 0.6149 - acc2: 0.8081 - val_loss: 0.0467 - val_acc0: 0.3598 - val_acc1: 0.6978 - val_acc2: 0.8833\n",
      "Epoch 2/200\n",
      "388/388 [==============================] - 1s 4ms/step - loss: 0.0489 - acc0: 0.3587 - acc1: 0.6829 - acc2: 0.8687 - val_loss: 0.0461 - val_acc0: 0.3787 - val_acc1: 0.6996 - val_acc2: 0.8837\n",
      "Epoch 3/200\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0474 - acc0: 0.3665 - acc1: 0.6936 - acc2: 0.8761 - val_loss: 0.0451 - val_acc0: 0.3666 - val_acc1: 0.7068 - val_acc2: 0.8924\n",
      "Epoch 4/200\n",
      "388/388 [==============================] - 1s 4ms/step - loss: 0.0459 - acc0: 0.3791 - acc1: 0.7044 - acc2: 0.8828 - val_loss: 0.0437 - val_acc0: 0.3838 - val_acc1: 0.7231 - val_acc2: 0.9006\n",
      "Epoch 5/200\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0445 - acc0: 0.3868 - acc1: 0.7125 - acc2: 0.8940 - val_loss: 0.0433 - val_acc0: 0.3819 - val_acc1: 0.7298 - val_acc2: 0.9030\n",
      "Epoch 6/200\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0441 - acc0: 0.3883 - acc1: 0.7202 - acc2: 0.8942 - val_loss: 0.0431 - val_acc0: 0.3859 - val_acc1: 0.7257 - val_acc2: 0.9022\n",
      "Epoch 7/200\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0437 - acc0: 0.3906 - acc1: 0.7226 - acc2: 0.8985 - val_loss: 0.0428 - val_acc0: 0.3875 - val_acc1: 0.7320 - val_acc2: 0.9077\n",
      "Epoch 8/200\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0432 - acc0: 0.3935 - acc1: 0.7259 - acc2: 0.9001 - val_loss: 0.0426 - val_acc0: 0.3875 - val_acc1: 0.7351 - val_acc2: 0.9079\n",
      "Epoch 9/200\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.0431 - acc0: 0.3957 - acc1: 0.7273 - acc2: 0.8996 - val_loss: 0.0426 - val_acc0: 0.3927 - val_acc1: 0.7268 - val_acc2: 0.9058\n",
      "Epoch 10/200\n",
      "388/388 [==============================] - 2s 6ms/step - loss: 0.0429 - acc0: 0.3941 - acc1: 0.7305 - acc2: 0.9035 - val_loss: 0.0425 - val_acc0: 0.3880 - val_acc1: 0.7339 - val_acc2: 0.9109\n",
      "Epoch 11/200\n",
      "388/388 [==============================] - 2s 6ms/step - loss: 0.0426 - acc0: 0.3954 - acc1: 0.7311 - acc2: 0.9019 - val_loss: 0.0424 - val_acc0: 0.3943 - val_acc1: 0.7239 - val_acc2: 0.9106\n",
      "Epoch 12/200\n",
      "388/388 [==============================] - 2s 6ms/step - loss: 0.0425 - acc0: 0.3986 - acc1: 0.7343 - acc2: 0.9030 - val_loss: 0.0424 - val_acc0: 0.3922 - val_acc1: 0.7351 - val_acc2: 0.9084\n",
      "Epoch 13/200\n",
      "388/388 [==============================] - 2s 6ms/step - loss: 0.0423 - acc0: 0.3995 - acc1: 0.7332 - acc2: 0.9056 - val_loss: 0.0424 - val_acc0: 0.3888 - val_acc1: 0.7343 - val_acc2: 0.9077\n",
      "Epoch 14/200\n",
      "388/388 [==============================] - 2s 6ms/step - loss: 0.0422 - acc0: 0.4008 - acc1: 0.7367 - acc2: 0.9050 - val_loss: 0.0424 - val_acc0: 0.3969 - val_acc1: 0.7339 - val_acc2: 0.9051\n",
      "Epoch 15/200\n",
      "388/388 [==============================] - 3s 7ms/step - loss: 0.0421 - acc0: 0.4033 - acc1: 0.7348 - acc2: 0.9064 - val_loss: 0.0423 - val_acc0: 0.3955 - val_acc1: 0.7304 - val_acc2: 0.9043\n",
      "Epoch 16/200\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.0420 - acc0: 0.3975 - acc1: 0.7358 - acc2: 0.9070 - val_loss: 0.0423 - val_acc0: 0.3940 - val_acc1: 0.7338 - val_acc2: 0.9055\n",
      "Epoch 17/200\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0417 - acc0: 0.3976 - acc1: 0.7382 - acc2: 0.9086 - val_loss: 0.0423 - val_acc0: 0.3825 - val_acc1: 0.7394 - val_acc2: 0.9096\n",
      "Epoch 18/200\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0416 - acc0: 0.4022 - acc1: 0.7398 - acc2: 0.9099 - val_loss: 0.0421 - val_acc0: 0.3950 - val_acc1: 0.7364 - val_acc2: 0.9072\n",
      "Epoch 19/200\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0415 - acc0: 0.4016 - acc1: 0.7396 - acc2: 0.9097 - val_loss: 0.0422 - val_acc0: 0.3921 - val_acc1: 0.7365 - val_acc2: 0.9084\n",
      "Epoch 20/200\n",
      "388/388 [==============================] - 2s 4ms/step - loss: 0.0413 - acc0: 0.4028 - acc1: 0.7434 - acc2: 0.9100 - val_loss: 0.0419 - val_acc0: 0.3958 - val_acc1: 0.7414 - val_acc2: 0.9096\n",
      "Epoch 21/200\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.0412 - acc0: 0.4077 - acc1: 0.7427 - acc2: 0.9130 - val_loss: 0.0419 - val_acc0: 0.3974 - val_acc1: 0.7407 - val_acc2: 0.9080\n",
      "Epoch 22/200\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.0410 - acc0: 0.4046 - acc1: 0.7468 - acc2: 0.9121 - val_loss: 0.0421 - val_acc0: 0.3982 - val_acc1: 0.7375 - val_acc2: 0.9061\n",
      "Epoch 23/200\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.0411 - acc0: 0.4020 - acc1: 0.7445 - acc2: 0.9145 - val_loss: 0.0421 - val_acc0: 0.3964 - val_acc1: 0.7338 - val_acc2: 0.9082\n",
      "Epoch 24/200\n",
      "388/388 [==============================] - 2s 5ms/step - loss: 0.0409 - acc0: 0.4075 - acc1: 0.7475 - acc2: 0.9123 - val_loss: 0.0421 - val_acc0: 0.3945 - val_acc1: 0.7389 - val_acc2: 0.9076\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(patience=4, verbose=1)]\n",
    "batch_size = 64\n",
    "max_epochs = 200\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, validation_data=(x_test, y_test), epochs=max_epochs, callbacks=callbacks)\n",
    "\n",
    "# decreasing, no p, flattened, 100e\n",
    "\n",
    "# decreasing, p=.4, flattened, 28e\n",
    "# loss: 0.0396 - acc0: 0.4144 - acc1: 0.7597 - acc2: 0.9229 - val_loss: 0.0414 - val_acc0: 0.3925 - val_acc1: 0.7375 - val_acc2: 0.9140\n",
    "\n",
    "# decreasing, p=.4, 3d, 24e\n",
    "# loss: 0.0409 - acc0: 0.4075 - acc1: 0.7475 - acc2: 0.9123 - val_loss: 0.0421 - val_acc0: 0.3945 - val_acc1: 0.7389 - val_acc2: 0.9076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.round(model.predict(x_test[99][np.newaxis, :]) * 100))\n",
    "# print(y_test[99])\n",
    "y_true = y_test[[2, 4, 8, 16, 32]]\n",
    "y_pred = model.predict(x_test[[2, 4, 8, 16, 32]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]], shape=(5, 17), dtype=int8) tf.Tensor(\n",
      "[[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]], shape=(5, 17), dtype=int8)\n",
      "tf.Tensor([7 8 7 8 6], shape=(5,), dtype=int64) tf.Tensor([8 9 6 7 6], shape=(5,), dtype=int64)\n",
      "tf.Tensor([False False False False  True], shape=(5,), dtype=bool) tf.Tensor(1.0, shape=(), dtype=float32) tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.2, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred_thresh = tf.cast(y_pred >= .5, 'int8')\n",
    "true_thresh = tf.cast(y_true >= .5, 'int8')\n",
    "print(pred_thresh, true_thresh)\n",
    "\n",
    "# Since tf.argmin returns the lowest index possible, this gets us the index of the last True value.\n",
    "# Note that this is -1 if the network doesn't many any prediction at all.\n",
    "pred_idx = tf.argmin(pred_thresh, axis=-1) - 1\n",
    "true_idx = tf.argmin(true_thresh, axis=-1) - 1\n",
    "print(pred_idx, true_idx)\n",
    "\n",
    "distance_bools = tf.abs(pred_idx - true_idx) <= 0\n",
    "correct = tf.reduce_sum(tf.cast(distance_bools, 'float32'))\n",
    "incorrect = tf.reduce_sum(tf.cast(tf.logical_not(distance_bools), 'float32'))\n",
    "print(distance_bools, correct, incorrect)\n",
    "\n",
    "print(correct / (correct+incorrect))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('venv': venv)",
   "language": "python",
   "name": "python38264bitvenvvenv62f2ef13a99a49ca88eefe3bb4a02605"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
